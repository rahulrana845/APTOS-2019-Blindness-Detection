{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'test_images', 'train.csv', 'sample_submission.csv', 'train_images']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3662 entries, 0 to 3661\n",
      "Data columns (total 2 columns):\n",
      "id_code      3662 non-null object\n",
      "diagnosis    3662 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 57.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2930 validated image filenames belonging to 5 classes.\n",
      "Found 732 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_df['diagnosis'] = train_df['diagnosis'].astype('str')\n",
    "train_df['id_code'] = train_df['id_code'].astype(str)+'.png'\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen=ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    validation_split=0.2)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_gen=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"../input/train_images\",\n",
    "    x_col=\"id_code\",\n",
    "    y_col=\"diagnosis\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(160,160),\n",
    "    subset='training')\n",
    "\n",
    "test_gen=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"../input/train_images\",\n",
    "    x_col=\"id_code\",\n",
    "    y_col=\"diagnosis\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\", \n",
    "    target_size=(160,160),\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['diagnosis']\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\",\n",
    "\t\t\tinput_shape=(160,160,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding=\"valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"valid\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es= EarlyStopping(monitor='val_loss', mode ='min', verbose = 0, patience = 20)\n",
    "mc = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "92/92 [==============================] - 424s 5s/step - loss: 1.4915 - acc: 0.5300 - val_loss: 2.7040 - val_acc: 0.4057\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 372s 4s/step - loss: 1.0496 - acc: 0.6286 - val_loss: 1.0777 - val_acc: 0.6366\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 371s 4s/step - loss: 0.9246 - acc: 0.6662 - val_loss: 1.0171 - val_acc: 0.6175\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - 373s 4s/step - loss: 0.9213 - acc: 0.6791 - val_loss: 0.9333 - val_acc: 0.6735\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - 368s 4s/step - loss: 0.8915 - acc: 0.6878 - val_loss: 0.8725 - val_acc: 0.6776\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - 372s 4s/step - loss: 0.8191 - acc: 0.7067 - val_loss: 0.8744 - val_acc: 0.6339\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - 370s 4s/step - loss: 0.8171 - acc: 0.7026 - val_loss: 0.8740 - val_acc: 0.6653\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - 368s 4s/step - loss: 0.8251 - acc: 0.7051 - val_loss: 0.8670 - val_acc: 0.6885\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - 369s 4s/step - loss: 0.8067 - acc: 0.7026 - val_loss: 0.8621 - val_acc: 0.6503\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - 367s 4s/step - loss: 0.7690 - acc: 0.7129 - val_loss: 0.8330 - val_acc: 0.7077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5bcc3629b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_gen,              \n",
    "                                    steps_per_epoch=len(train_gen),\n",
    "                                    validation_data=test_gen,                    \n",
    "                                    validation_steps=len(test_gen),\n",
    "                                    epochs=10,\n",
    "                                    callbacks = [es, mc], \n",
    "                                    use_multiprocessing = True,\n",
    "                                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('../input/sample_submission.csv')\n",
    "#submission_df['diagnosis'] = submission_df['diagnosis'].astype('str')\n",
    "submission_df['id_code'] = submission_df['id_code'].astype(str)+'.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1928 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "submission_datagen=ImageDataGenerator(rescale=1./255)\n",
    "submission_gen=submission_datagen.flow_from_dataframe(\n",
    "    dataframe=submission_df,\n",
    "    directory=\"../input/test_images\",\n",
    "    x_col=\"id_code\",    \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode=None, \n",
    "    target_size=(160,160)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict_generator(submission_gen, steps = len(submission_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_probability = np.argmax(predictions,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['diagnosis'] = max_probability\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
